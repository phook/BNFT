alpha_char:
"A".."Z"
 "a".."z"

numeric_char:
 "0".."9"

hexadecimal_char:
 numeric_char
 "A".."F"
 "a".."f"

alphanumeric_char:
 numeric_char
 alpha_char

any_char:
 "\\t" 
 "\\r" 
 "\\n" 
 "\\\\" 
 "\\\"" 
 "\\\’" 
 "#".."+"
 " " | "!"
 "(".."\0xFFFF"
 "\\0x" hexadecimal_char
 "\\0x" hexadecimal_char hexadecimal_char hexadecimal_char hexadecimal_char 
 
whitespace:
 " "
 "\t"

whitespaces:
 { whitespace }

identifier:
 alpha_char { alphanumeric_char | "_"} { whitespace }

newline:
 "\r\n"
 "\n\r"
 "\r"
 "\n"
 ";"

newlines:
 whitespaces newline whitespaces { newlines }
 
entry:
 identifier ":" newlines { definition newlines }    -> "this." identifier " = function () {" definition "}" 
 identifier whitespaces "=" definition newlines     -> "this." identifier " = function () {" definition "}"

literal:
 "\"" { any_char } "\"" whitespaces [".." whitespaces "\"" { any_char } "\""]
 "\’" { any_char } "\’" whitespaces [".." whitespaces "\'" { any_char } "\'"]

output_literal:
 "\"" { any_char } "\"" whitespaces
 "\’" { any_char } "\’" whitespaces

definition:
 expression [  {newline | whitespace} "->" {newline | whitespace} output]

item:
 literal
 identifier
 "{" expression "}"
 "[" expression "]"
 "(" expression ")" 

or_expression:
 whitespaces item { whitespaces "|"  or_expression }

expression:
 whitespaces or_expression { whitespaces or_expression }

output:
 "#indent" | "#block" [output]
 output_literal [output]
 identifier [output] 

body:
 { "#include" {whitespace} literal } 
 { entry } 

script:
  { body } -> '
    var Tokenizer = function (source) {
      this.source = source;
      this.position = 0; // current position (or current peekposition if peeking)

      this.peekPosition = []; // for storing current position when peeking
      this.indents = []; // for indents - significant whitespace

      this.endOfScript = function () {
        return this.position >= source.length;
      };

      // returns next char and advances position
      this.nextChar = function () {
        var result = this.currentChar();
        this.next();
        return result;
      };

      // advances position
      this.next = function () {
        this.position += 1;
      };

      // returns current char
      this.currentChar = function () {
        if (this.position >= this.source.length) {
          return "";
        }
        return this.source.substring(this.position, this.position + 1);
      };

      // returns if peeking is active
      this.peeking = function () {
        return this.peekPosition.length !== 0;
      };

      // push/start peeking
      this.peek = function () {
        this.peekPosition.push(this.position);
      };

      // pop/stop peeking
      this.unPeek = function () {
        if (this.peeking()) {
          this.position = this.peekPosition.pop();
        }
      };

      // checks for next token to be s and advances position
      this.nextIs = function (s, caseSensitive) {

        caseSensitive = (caseSensitive === undefined) ? true : caseSensitive;

        if (this.peekNextIs(s, caseSensitive)) {
          this.position += s.length;
          return true;
        }
        return false;
      };

      // checks for next token to be s
      this.peekNextIs = function (s, caseSensitive) {

        caseSensitive = (caseSensitive === undefined) ? true : caseSensitive;

        if (this.position + s.length > this.source.length) {
          return false;
        }

        var match = this.source.substring(this.position, this.position + s.length);

        if (caseSensitive) {
          return match === s;
        }

        return match.toLowerCase() === s.toLowerCase();
      };

      // inserts a string at mark
      this.insertFrom = function (mark, stringToInsert) {
        this.source = source.substring(0, mark) + stringToInsert + "\n" + source.substring(this.position);
        this.position = mark;
      };
    };

    var tokenizer = new Tokenizer(source + "\n");
' body


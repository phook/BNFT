alpha_char:
 "A".."Z"
 "a".."z"

numeric_char:
 "0".."9"

hexadecimal_char:
 numeric_char
 "A".."F"
 "a".."f"

alphanumeric_char:
 numeric_char
 alpha_char

any_char:
 "\\\"" 
 "\\\'" 
 "\\t"
 "\\r" 
 "\\n" 
 "\\\\" 
 "#".."+"
 " " | "!"
 "(".."\0xFFFF"
 "\\0x" hexadecimal_char
 "\\0x" hexadecimal_char hexadecimal_char hexadecimal_char hexadecimal_char 
 newline
 whitespace
 
whitespace:
 " " | "\t"  { " " | "\t" }

optwhitespace:
 [ whitespace ] 

newline:
 "\r" | "\n" | ";" { " " | "\t" | "\r" | "\n" | ";" }

optnewline:
 [ newline ]

identifier:
 alpha_char { alphanumeric_char | "_"}

newline:
 "\r\n"
 "\n\r"
 "\r"
 "\n"
 

newlines:
 optwhitespace newline { optwhitespace newline }
 
entry:
 identifier ":" newlines { definition newlines }    -> "this." identifier " = function () {" definition "}" 
 identifier optwhitespace "=" definition newlines     -> "this." identifier " = function () {" definition "}"

literal:
  "\"" { any_char } "\"" 
  "\'" { any_char } "\'"

range:
 literal optwhitespace ".." literal

output_literal:
 "\"" { any_char } "\"" 
 "\'" { any_char } "\'" 

definition:
 expression [ optwhitespace "->" optwhitespace output]

item:
 range
 literal
 identifier
 "{" expression optwhitespace "}"
 "[" expression optwhitespace "]"
 "(" expression optwhitespace ")" 

or_expression:
 optwhitespace item { optwhitespace "|"  or_expression }

expression:
 optwhitespace or_expression { optwhitespace or_expression }

output_item:
 "#indent" | "#block"
 output_literal
 identifier 

output:
  output_item { whitespace output_item }

body:
 { "#include" {whitespace} literal } 
 { entry } 

script:
  { body } -> '
    var Tokenizer = function (source) {
      this.source = source;
      this.position = 0; // current position (or current peekposition if peeking)

      this.peekPosition = []; // for storing current position when peeking
      this.indents = []; // for indents - significant whitespace

      this.endOfScript = function () {
        return this.position >= source.length;
      };

      // returns next char and advances position
      this.nextChar = function () {
        var result = this.currentChar();
        this.next();
        return result;
      };

      // advances position
      this.next = function () {
        this.position += 1;
      };

      // returns current char
      this.currentChar = function () {
        if (this.position >= this.source.length) {
          return \"\";
        }
        return this.source.substring(this.position, this.position + 1);
      };

      // returns if peeking is active
      this.peeking = function () {
        return this.peekPosition.length !== 0;
      };

      // push/start peeking
      this.peek = function () {
        this.peekPosition.push(this.position);
      };

      // pop/stop peeking
      this.unPeek = function () {
        if (this.peeking()) {
          this.position = this.peekPosition.pop();
        }
      };

      // checks for next token to be s and advances position
      this.nextIs = function (s, caseSensitive) {

        caseSensitive = (caseSensitive === undefined) ? true : caseSensitive;

        if (this.peekNextIs(s, caseSensitive)) {
          this.position += s.length;
          return true;
        }
        return false;
      };

      // checks for next token to be s
      this.peekNextIs = function (s, caseSensitive) {

        caseSensitive = (caseSensitive === undefined) ? true : caseSensitive;

        if (this.position + s.length > this.source.length) {
          return false;
        }

        var match = this.source.substring(this.position, this.position + s.length);

        if (caseSensitive) {
          return match === s;
        }

        return match.toLowerCase() === s.toLowerCase();
      };

      // inserts a string at mark
      this.insertFrom = function (mark, stringToInsert) {
        this.source = source.substring(0, mark) + stringToInsert + \"\n\" + source.substring(this.position);
        this.position = mark;
      };
    };

    var tokenizer = new Tokenizer(source + \"\n\");
' body

